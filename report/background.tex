The Background consists of a quick introduction to the most important quantum mechanical concepts and notation. Readers familiar with quantum mechanics may skip it. The second part explores the fundamentals of quantum computation and 

\subsection{Basic quantum mechanics, part I}
This part offers a quick introduction to the necessary quantum mechanics for readers whom are not familiar with the subject. Quantum mechanics is nothing more than linear algebra with fancy notation and some additional rules. The section contains nothing relevant for later parts of the thesis and can be safely skipped. For a more complete introduction I suggest chapter 1 of Sakurai.


\subsubsection{Quantum states and Dirac notation}
First lets define what is meant by the term \textbf{state}. In classical physics a state would be given by the position and momentum of all its individual constituents. An example would be a system of $N$ particles, the state would be given by $\{ (\vec{x}, \vec{p})_i \}_{i=1}^N$, where $\vec{x},\vec{p} \in \mathbb{R}^3$ are the position and momentum in 3 dimensions. In Quantum Mechanics (QM) it more subtle than this, since exact information of the system can not be obtained in the same way. So a state is represented by a normalized vector in a complex vector space. The vector space in which the state vector lives is called a \textbf{Hilbert space} and has the following properties. given two vectors $u,v$ in $H$ they satisfy:

\noindent The inner product is conjugate symmetric
\begin{enumerate}
\item $\inp{u}{v} = \overline{\inp{v}{u}} \in \mathbb{C}$
\end{enumerate}
The inner product is linear in the first argument, for constants $a,b\in \mathbb{C}$
\begin{enumerate}[resume]
\item $\inp{au_1 + bu_2}{v} = a\inp{u_1}{v} + b\inp{u_2}{v}$
\end{enumerate}
The inner product is positive definite 
\begin{enumerate}[resume]
\item $\inp{u}{u} = 0 \iff u = 0$
\end{enumerate}
These properties can be combined to find some other useful facts that holds,
combining the 1st and 2nd property,

\begin{equation}
\inp{v}{au_1 + bu_2} = \overline{\inp{au_1 + bu_2}{v}} = a^{*}\overline{\inp{u_1}{v}} + b^{*}\overline{\inp{u_2}{v}} =   a^{*}\inp{v}{u_1} + b^{*}\inp{v}{u_2}
\end{equation} 
the inner product is anti-linear in the second term.
Using the 1st and 3rd property 
\begin{equation}
\inp{u}{u} = \overline{\inp{u}{u}} \implies \text{Im}(\inp{u}{u}) = 0
\end{equation}
or in words, the inner product of two identical vectors is a real number.

So now we have established that a quantum state is a normalized vector $v$ in a Hilbert space $H$. Now a property of vector spaces is that any vector can be multiplied by a matrix, and the resulting vector will be a new vector in the same vector space. This is what is meant when a quantum state is \textbf{acted} upon. For a matrix $A$ we have that 
\begin{equation}
H \ni v  \xrightarrow{A} Av = v' \in H
\end{equation}
acting on a state alters it in various ways.

Now lets go from this linear algebra notation to the Dirac notation commonly used in quantum mechanics, also know as bra-ket notation.
Vectors are replaced by \textbf{kets},$\ket{}$, or \textbf{bras},$\bra{}$. 
$v \mapsto \ket{\psi}$ \\
$v^\dagger \mapsto \bra{\psi}$\\
and matrices are replaced by operators\\
$A \mapsto \hat{A}$\\
The same rules applies to these as for the usual vectors.
The label inside the brackets does no in itself have any meanings and are in some sense only just that, labels, but more often than not it is used to represent some property of the state. With this notation the inner product between to states $\ket{\psi},\ket{\varphi}$ is written as 
\begin{equation}
\bra{\psi}\ket{\varphi} = a_1^{*}b_1 + a_2^{*}b_2 + \dots + a_n^{*}b_n = \begin{pmatrix} a_1^{*} & a_2^{*} & \dots & a_n^{*}\end{pmatrix} \begin{pmatrix} b_1 \\ b_2 \\ \vdots \\ b_n\end{pmatrix}
\end{equation}
from the properties defined earlier the relations $(\ket{\psi})^\dagger = \bra{\psi}$ and $ (\bra{\psi}\ket{\varphi})^\dagger = \bra{\varphi}\ket{\psi}$,
this suggest that another way to define the states would simply be
\begin{equation}
\ket{\psi} = \begin{pmatrix}
a_1 \\ a_2 \\ \vdots \\ a_n
\end{pmatrix},\;
\bra{\psi} = (\ket{\psi})^{\dagger} = (a_1^{*}, a_2^{*}, \dots, a_n^{*}),\; a_1,a_2,\dots,a_n \in \mathbb{C}
\end{equation}
which is nothing more than a complex vector. A common way to represent kets is as a linear combination of eigenkets, which corresponds to the set of eigenvectors. Thus can any arbitrary ket be written as a linear combination of these kets if they span the space
\begin{equation}
\ket{A} = \sum_{a} c_{a}\ket{a}
\end{equation}
where the $\ket{a}$s span the space in which $\ket{A}$ lives.
\\
Following are some example calculations to see how to use Dirac-notation, lets consider what the effect of the Pauli-Z operator of a spin-$\dfrac{1}{2}$ particle is
\begin{enumerate}[label=\textbf{\alph*)}]
\item on the up position $\ket{\psi} = \ket{\downarrow}$?

\item on an arbitrary superposition of up and down $\ket{\psi} = \alpha \ket{\uparrow} + \beta\ket{\downarrow}, |\alpha|^2 + |\beta|^2 = 1, \alpha,\beta \in \mathbb{C}$?
\end{enumerate}
Lets first show how this would be done using the matrix representation and then using dirac notation.
Here the kets $\{\ket{\uparrow} \dot{=} \begin{pmatrix}
1 \\ 0
\end{pmatrix}, \, \ket{\downarrow} \dot{=} \begin{pmatrix}
0 \\ 1
\end{pmatrix} \}$ span the Hilbert space of the particle, they also form an orthonormal basis. The Pauli-Z operator in the matrix representation in this basis is $\sigma_z = \begin{pmatrix}
\,1 & 0 \\
0 & -1 \\
\end{pmatrix}$. Then we have that 

\begin{enumerate}[label = \textbf{\alph*)}]
\item We simply write out the matrices and vectors and get that \\$\sigma_z\ket{\psi} \dot{=} \begin{pmatrix}
\,1 & 0 \\
0 & -1 \\
\end{pmatrix}\begin{pmatrix}
0 \\ 1
\end{pmatrix} = \begin{pmatrix}
0 \\ -1
\end{pmatrix} \dot{=} -\ket{\downarrow}$ 

\item Same as before but with a superposition (linear combination) up and down 
\\$\sigma_z\ket{\psi} \dot{=} \begin{pmatrix}
\,1 & 0 \\
0 & -1 \\
\end{pmatrix}\left[\alpha\begin{pmatrix}
1 \\ 0
\end{pmatrix} + \beta\begin{pmatrix}
0 \\ 1
\end{pmatrix} \right]= \begin{pmatrix}
\alpha \\ -\beta
\end{pmatrix}  = \alpha\begin{pmatrix}
1 \\ 0
\end{pmatrix} -\beta\begin{pmatrix}
0 \\ 1
\end{pmatrix} \dot{=}\, \alpha\ket{\uparrow} - \beta\ket{\downarrow}$ \end{enumerate}
The matrix representation works great for small Hilbert spaces, lets do it again now using Dirac notation, here the inner product will be a key aspect, and making use of the orthonormality of $\ket{\uparrow},\ket{\downarrow}$ it follow that $\bra{\uparrow}\ket{\uparrow} = \bra{\downarrow}\ket{\downarrow} = 1$ and $\bra{\uparrow}\ket{\downarrow} = \bra{\downarrow}\ket{\uparrow} = 0$.
With Dirac notation operators can be expressed as outer products of bras and kets, thus Pauli-Z can be written as $\sigma_z = \ket{\uparrow}\bra{\uparrow} - \ket{\downarrow}\bra{\downarrow}$.

\begin{enumerate}[label=\textbf{\alph*)}]
\item  $\sigma_z \ket{\psi} = (\ket{\uparrow}\bra{\uparrow} - \ket{\downarrow}\bra{\downarrow})\ket{\downarrow} = \ket{\uparrow}\underbrace{\bra{\uparrow}\ket{\downarrow}}_{ = 0} - \ket{\downarrow}\underbrace{\bra{\downarrow}\ket{\downarrow}}_{ = 1} = 0\ket{\uparrow} - 1\ket{\downarrow} = -\ket{\downarrow}$.
\item $\sigma_z \ket{\psi} = \left( \ket{\uparrow}\bra{\uparrow} - \ket{\downarrow}\bra{\downarrow} \right) \left(\alpha\ket{\uparrow} + \beta\ket{\downarrow} \right) = 
\alpha\ket{\uparrow}\underbrace{\bra{\uparrow}\ket{\uparrow}}_{ = 1} - \alpha\ket{\downarrow}\underbrace{\bra{\downarrow}\ket{\uparrow}}_{ = 0}
+
\beta\ket{\uparrow}\underbrace{\bra{\uparrow}\ket{\downarrow}}_{ = 0} - \beta\ket{\downarrow}\underbrace{\bra{\downarrow}\ket{\downarrow}}_{ = 1} = \alpha\ket{\uparrow} - \beta\ket{\downarrow}$.
\end{enumerate}
Note that the final answer is the same for both cases, but using Dirac notation there was no need to bother with explicit vectors, thats one of the strong advantages of the Dirac notation. These calculations are quite analogous to how a qubit works which will be discussed in a later section. 


\subsubsection{Probability amplitudes, Observables and Measurements}
\note{Write this}



\subsubsection{Time evolution and the Schr√∂dinger equation}
Say we have a time-dependent state $\ket{\psi(t)}$, how does the system evolve when time goes from $t_0$ to some later time $t_1$, 
\begin{equation}
\ket{\psi(t_0)} \xrightarrow{t_0 \mapsto t_1} \ket{\psi(t_1)} 
\end{equation}
We can write this as an operator equation $\mathcal{U}(t,t_0)\ket{\psi(t_0)} = \ket{\psi(t)}$. To be a valid operator $\mathcal{U}$ must satisfy some properties. To preserve probability the operator must be unitary, $\mathcal{U}^\dagger\mathcal{U} = \mathcal{U}\mathcal{U}^\dagger = 1$.
The second property that need to be fulfilled is composition, $\mathcal{U}(t_2,t_0) = \mathcal{U}(t_2,t_1)\mathcal{U}(t_1,t_0)$, which is to say that applying to consecutive time transformations, first between $t_0 \rightarrow t_1$ and then $t_1 \rightarrow t_2$ is equivalent with applying one transformation between $t_0 \rightarrow t_2$. 
Proceeding lets define how the time evolution operator would act under an infinitesimal change $dt$, lets propose an operator on the form
\begin{equation}
\mathcal{U}(t_0 +dt, t_0) = \mathbf{1} - i\,\Omega\,dt
\end{equation}
with $\Omega$ being hermitian, $\Omega = \Omega^\dagger$. $\Omega$ can be time dependent, and then must be evaluated at $t_0$. As $dt$ approaches $0$ it reduces to an identity operator, which is appropriate.
Lets check the two other properties
\begin{enumerate}
\item identity
\end{enumerate}
\begin{equation}
\mathcal{U}(t_0 +dt, t_0)\mathcal{U}(t_0 +dt, t_0)^\dagger = \left( \mathbf{1} - i\,\Omega\,dt \right)\left(\mathbf{1} + i\,\Omega\,dt \right) = \mathbf{1} + i\,\Omega\,dt - i\,\Omega\,dt + \mathcal{O}(dt^2) \simeq \mathbf{1}
\end{equation}
\begin{enumerate}[resume]
\item Composition
\end{enumerate}
\begin{equation}
\mathcal{U}(t_0 + dt_1 + dt_2,t_0 + dt_1)\mathcal{U}(t_0 + dt_1,t_0) = (\mathbf{1} - i\,\Omega\,dt_2)(\mathbf{1} - i\,\Omega\,dt_1) = \mathbf{1} - i\,\Omega\,dt_1 - i\,\Omega\,dt_2)(\mathbf{1} + \mathcal{O}(dt^2) \simeq \mathbf{1} - i\,\Omega(dt_1 + dt_2) = \mathcal{U}(t_0 + dt_1 + dt_2,t_0).
\end{equation}
The operator $\Omega$ happens \note{why?} to match with the Hamiltonian operator $H$ by a numerical factor, $\Omega = \frac{H}{\hbar}$, where $\hbar$ is Plancks reduced constant. So for an infinitesimal time shift the operator has the form $\mathcal{U}(t_0 + dt, t_0) = \mathbf{1} - i\,\frac{H}{\hbar} \,dt$
\\
\note{some smooth segway}
\\
One of Quantum Mechanics postulates is that a closed quantum state evolves according to the Schr√∂dinger equation, Equation \ref{eq:schro}, here it becomes more obvious why it happens that $\Omega$ was related to the Hamiltonian. It is common to set $\hbar = 1$, as it is just a numerical shift, so lets do that, which simplifies both the Schr√∂dinger equation and the time evolution operator $\mathcal{U}$. 
\begin{equation} 
i \hbar \pdv{}{t} \ket{\psi(t)} = H \ket{\psi(t)}
\label{eq:schro}
\end{equation} 
Now its is clear that the time evolution operator is related to the Schr√∂dinger equation in some way, notice that the solution $\ket{\psi(t)}$ can be written in terms of our time evolution operator as
$\ket{\psi(t)} = \mathcal{U}(t,t_0)\ket{\psi(t_0)}$. So given an initial condition we have solved the Schr√∂dinger equation if we can determine $\mathcal{U}(t,t_0)$.  
To find the time evolution operator for any time $t$, we could successively repeat the infinitesimal operator until the desired time is reached $t_0 \mapsto t_0 + dt \mapsto t_0 + 2\,dt \mapsto \dots \mapsto t - dt \mapsto t$. For the case of a time independent Hamiltonian $H$ it could be written as
\begin{equation}
\lim_{N \rightarrow \infty} \left(\mathbf{1} - i\,H\frac{(t-t_0)}{N} \right)^N = \exp\left(- i\,H(t-t_0) \right)
\end{equation}
For simplicity lets assume that $t_0 = 0$, then the time evolution operator for a finite time for a time independent Hamiltonian could be written as $\mathcal{U}(t,0) = e^{-i\,H\,t}$. If the Hamiltonian has time dependence but it commutes with itself at different times, then a integral can be introduces in the exponential, $\mathcal{U}(t,0) = e^{-i\,\int_0^t \,H(t')\, dt'}$, if the Hamiltonian does not commute at different times it becomes a bit more involved and will not be covered here. 

To conclude, finding the time evolution operator corresponds to finding the solution to the Schr√∂dinger Equation, which governs time evolution of quantum systems.








\subsection{Quantum Computation and Quantum Information theory, part 2}

\subsubsection{The Qubit}
A classical bit is a two state (binary) system, which means it can, occupy either one of two states, \textbf{0} or \textbf{1}. So with $n$ bits there is $2^n$ possible states that can be represented, but only one at a time.

The general way to define a qubit would be any two dimensional quantum system ($\text{dim}(\mathcal{H}) = 2$). In the orthonormal basis ${\ket{0},\ket{1}}$. Where qubits are on the form given in Equation \ref{eq:qubit}, any super position (linear combination) of the basis-kets $\ket{0},\ket{1}$.
\begin{equation}
\label{eq:qubit}
\ket{\psi} = \alpha\ket{0} + \beta\ket{1},\,\alpha,\beta \in \mathbb{C},\, |\alpha|^2 + |\beta|^2 = 1.
\end{equation}
For most of the time it is better to work with the abstract concept of qubits without focusing on the physical implementation, we however see a lot of similarities with spin-$\dfrac{1}{2}$ particles ($\ket{\downarrow},\ket{\uparrow}$) or energy levels in a trapped ion ($\ket{g},\ket{e}$). There is no need to limit the system to a physical 2 dimensional system. Simply choose two appropriate states which form a 2 dimensional subspace.

The coefficients $\alpha$ and $\beta$ are the probability amplitudes, and tells with what probability one will find either $\ket{0}$ or $\ket{1}$ when measuring. One finds $\ket{0}$,$\ket{1}$ with probability $|\alpha|^2$ and $|\beta|^2$ respectively.

The consequence of superposition is that the qubit is not limited to just either 0 or 1, this in combination with other QM effects is what is used to create classically impossible algorithms\cite{shor}\cite{Grover}.

The combined state of two qubits $\ket{\psi_1}$ and $\ket{\psi_2}$ is given by 
\begin{equation}
\ket{\psi_1} \otimes \ket{\psi_2} = (\alpha_1\ket{0} + \beta_1\ket{1})\otimes(\alpha_2\ket{0} + \beta_2\ket{1})
\end{equation}
the tensor product is often omitted and one would write $\ket{\psi_1} \otimes \ket{\psi_2} = \ket{\psi_1}\ket{\psi_2} = \ket{\psi_1, \psi_2}$.
So $n$ qubits is often written as $\ket{x}^{\otimes n},\, x \in \{0,1\}$ which is spanned by kets on the form $\ket{x_0x_1x_2...x_n},\, x_i \in \{0,1\}$, representing all possible bit strings of length $n$.

\subsubsection{From Classical Logic Gate to Quantum Gate}
A model used in classical computation is the circuit model, which consists of wires and logic gates. The wires carry the bit information, \textbf{0}, \textbf{1}, and the gates apply different operations. A common gate is the {\textit NOT}-gate which flips the content of the bit $NOT(\textbf{0}) = 1$ and $NOT(\textbf{1}) = 0$, some other common logic gates are shown in Table \ref{tab:gates}. 

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \multicolumn{2}{|c|}{Input} & {\tt AND} & {\tt NAND} & {\tt OR}\\
    \hline
    0 & 0 & 0& 1& 0\\
    0 & 1 & 0& 1& 1\\
    1 & 0 & 0& 1& 1\\
    1 & 1 & 1& 0& 1\\
    \hline
    \end{tabular}
    \caption{Some common classical logic gates}
    \label{tab:gates}
\end{table}


To make logic gates suitable for quantum computation the classical logic gate has to be adjusted. A quantum gate has some desired properties
\begin{enumerate}
\item Reversibility 
\item Conservation of probability
\end{enumerate}
it will turn out that these properties more or less has the same consequence. The first property is not achieved by the classical gates. For example, given the output of the \textbf{AND}-gate it is impossible to to know the state of the bits that went in to the gate. An output of \textbf{1} only conveys that the inputs were equal, \textbf{1},\textbf{1} or \textbf{0},\textbf{0}, but not which one. Adding another output that simply is one of the input can make the gate reversible, if you get a \textbf{0} as output, and know that the first input was \textbf{0}, then the second input must be must be a \textbf{1}. This extends to all inputs and outputs. In the quantum mechanical context a quantum logic gate is an quantum operator acting on the state of the qubit. $A\ket{\psi} = \ket{\psi'}$, so the equivalence of the classical reversibility would be the existence of an inverse operator $A^{-1}$ such that the operation could be reversed $A^{-1}\ket{\psi'} = A^{-1}A\ket{\psi} = \mathbf{1}\ket{\psi} = \ket{\psi}$

Conservation of probability does not really have any classical analogue due to it being a quantum property. More concretely it means conservation of the inner product. Given the states $U\ket{\psi} = \ket{\psi'}$ and $U\ket{\varphi} = \ket{\varphi'}$, then the inner product of $ket{\psi},ket{\varphi}$ is the same as for $ket{\psi'},ket{\varphi'}$. Thus one can compute
\begin{equation}
\bra{\psi'}\ket{\varphi'} = \bra{\psi}U^\dagger U\ket{\varphi} = \bra{\psi}\ket{\varphi}
\end{equation}
and see that this only holds if $U^\dagger U = UU^\dagger = \mathbf{1}$, which happens to be the condition for $U$ to be a unitary operator. From the unitarity it is possible to also see that $U^\dagger = U^{-1}$. The reversibility is also a consequence of the operators being Unitary.

There are many ways to achieve creation and implementation of quantum gates, some of them will be discussed in more detail in the Section \note{Holonomic Quantum Computation?}, lets see in general how a quantum gate could be implemented. To apply a quantum gate to the qubit means to operate on a quantum state with a unitary operator. The time evolution operator discussed earlier happens to be unitary, and it acts on states according to the Schr√∂dinger. Since $U = e^{-i\,H,t}$, the time evolution operator is determined by the Hamiltonian. So by constructing a Hamiltonian, $H$, that gives $U$ the form of an operator it one could in that way apply a quantum gate.


\subsubsection{Some important gates and Universal computation}
To realize a quantum gate a unitary, $U$, is applied to the quantum state, a unitary operator has the property that $U^\dagger U = UU^\dagger = \mathbf{1}$, and conserves probability. 

Some of the most common gates are the Pauli gates, $X,Y,Z$, which are equivalent to the Pauli matrices, $\sigma_x,\sigma_y,\sigma_z$. 
They are defined as
\begin{equation}
X \dot{=}\begin{pmatrix}
0 & 1 \\ 1 & 0
\end{pmatrix},\; 
Y\dot{=}\begin{pmatrix}
0 & -i \\ i & 0
\end{pmatrix},\; 
Z \dot{=} \begin{pmatrix}
1 & 0 \\ 0 & -1
\end{pmatrix}
\end{equation}
together they span the $SU(2)$ group.  \note{something something}
It is more common to use $X$ and $Z$ since $Y = i\,X\,Z$. The $X$-gate is somewhat analogous to the classical {\tt NOT}-gate,  
with the effect that is swaps the input qubits, 
$\begin{cases} X\ket{0} = \ket{1}\\
X\ket{1} = \ket{0}
\end{cases}$.
The Z-gate introduces a phase-flip between the inputs, it does nothing to $\ket{0}$ and negates the sign of $\ket{1}$, $\begin{cases} Z\ket{0} = \ket{0}\\
Z\ket{1} = -\ket{0}
\end{cases}$.
 
Superposition is one of the key aspects that makes QC able to surpass classical algorithms. The Hadamard gate, $H$ creates a superimposed quantum state, and is widely used all over QC, the gate is defined as
\begin{equation}
H \dot{=} \dfrac{1}{\sqrt{2}}\begin{pmatrix}
1 & 1 \\ 1 & -1
\end{pmatrix}.
\end{equation}
Another noteworthy property is that $H$ is its own inverse, $HH = \mathbf{1}$, so it can be used both to open and close superposition. More explicitly, the gate effect is 
\begin{equation}
\begin{cases}
H\ket{0} = \dfrac{1}{\sqrt{2}}(\ket{0} + \ket{1})
\\
H\ket{1} = \dfrac{1}{\sqrt{2}}(\ket{0} - \ket{1})
\end{cases}
\begin{cases}
H\dfrac{1}{\sqrt{2}}(\ket{0} + \ket{1}) = \ket{0}
\\
H\dfrac{1}{\sqrt{2}}(\ket{0} - \ket{1}) = \ket{1}
\end{cases}.
\end{equation}
The well known quantum algorithms make heavy use out of this operator\cite{Grover}\cite{shor}, it is essential to QC.
The concept of the phase flip, $Z$, can be extended to a phase shift of any arbitrary angle, the gate is denoted by $P(\phi)$ or sometimes simply $\phi$. It is defined as 
\begin{equation}
P(\phi) \dot{=} \begin{pmatrix}
1 & 0 \\
0 & e^{i\phi}.
\end{pmatrix}
\end{equation}
Then $Z$ reduces to the case $P(\pi) = Z$, some other notable cases of the phase shift are the $T$ and $S$ gates, defined by
\begin{equation}
T = P({\pi/4}) \dot{=} \begin{pmatrix}
1 & 0 \\ 0 & e^{i\pi/4}
\end{pmatrix},\, S = T^2 = P({\pi/2}) \dot{=} \begin{pmatrix}
1 & 0 \\ 0 & e^{i\pi/2}
\end{pmatrix}.
\end{equation}

All gates so far a single-qubit gates, to achieve full universality it turns out that two qubit-gates are enough. The two qubit gate used is the {\tt CNOT}, which stands for controlled not, the effect is defined as ${\tt CNOT}\ket{x,y} = \ket{x,x\oplus y}$, where $\oplus$ denotes addition mod 2. The gate takes two inputs, the control and the target. If the control is $\ket{1}$ then a {\tt NOT} is applied to the target $\ket{y} \mapsto X\ket{y}$, otherwise the gate leaves the inputs unchanged.



\subsubsection{Qudit Generalizations}
Inherently there are nothing special about bits and binary logic, same goes for qubits.  A qudit is the general name for a higher dimensional qubit, often with dimension $d$, the special case of $d = 3 
$ is called a \textit{qutrit}, $d = 4$ a \textit{ququart} and so on. A bigger computational basis could even prove to be better in some sense. The information content per unit is higher, $N$ qubits can be reduced down to $\dfrac{N}{\log_2(d)}$ qudits\cite{info_qudit}, with quickly diminishing returns. The qutrit has a reduction factor of $\sim 0.64$, the ququart $0.5$, with less returns the higher the dimension. Due to more information per unit, less operations are required to build quantum gates, minimizing the loss of accuracy from operations. The toffoli gate can be constructed with only BLANK gates using qutrits, which need BLANK gates with qubits \note{reference and lookup actual numbers}. The drawback is the increased complexity in the schemes for physical implementation which could come with increased errors. There are already many promising results using qudits\cite{qutrit1}\cite{qudit2}\cite{qudit3}, and many more are discussed in \cite{qudit}. The question is if the benefits of qudits can outweight the extra cost.

In the following section let, let the dimension $d$ be any integer such that $d > 2$, some generalized qudits gates will be defined and discussed, the definitions used are the same used in \cite{qudit}.
The effect of {\tt NOT} is ambiguous for when the number of basis states are more than 2. So instead of viewing it as NOT, it can be thought of as a permutation of the states $\ket{0},\ket{1}$. The higher dimensional correspondence of $X$ is defined as
\begin{equation}
X_d = \begin{pmatrix}
0 & 0 & \dots & 0 & 1\\
1 & 0 & \dots & 0 & 0\\
0 & 1 & \dots & 0 & 0\\
\vdots & \vdots &\ddots& \vdots&\vdots\\
0 & 0& \dots & 1 & 0
\end{pmatrix}.
\end{equation}
The effect works as a permutation of basis states, for $d = 3$, the effect would be $\ket{0} \xrightarrow{X_3} \ket{1} \xrightarrow{X_3} \ket{2} \xrightarrow{X_3} \ket{0}$.
The higher dimensional $Z$-gate $Z_d$ is defined as 
\begin{equation}
Z_d = \begin{pmatrix}
1 & 0 & 0 & \dots & 0 \\
0 & \omega & 0 &\dots & 0\\
0 & 0 & \omega^2&\dots & 0 \\
\vdots & \vdots&\vdots&\ddots& 0\\
0 & 0& 0&\dots  & \omega^{d-1}
\end{pmatrix}
\end{equation}

with $\omega = \sqrt[d]{1} = e^{2\pi i/d}$ being the $d$th roots of unity. It shift the different basis a certain amount.

The generalized version of the Hadamard gate for qudits $H_d$ easier to define of how it acts on each basis-ket, the effect is 
\begin{equation}
H_d\ket{j} = \dfrac{1}{\sqrt{d}}\sum_{i=0}^{d-1} \omega^{i\,j}\ket{i},\; j\in \{0,1,2, \dots, d-1\}
\end{equation}
with $\omega$ still the $d$th root of unity.

Last lets define the generalized qudit $T$-gate, now $d$ is restricted to prime numbers, such $T_d$ is only defined for prime number dimensions\note{lookup why and cite}. 
The gate is defined by
\begin{equation}
T_d = \sum_{k=0}^{d-1} \omega^{\nu_k}\ket{k}\bra{k}
\end{equation}

with $\omega$ being the $d$th root of unity. The exponent $\nu_k$ can be is defined by
\begin{equation}
\begin{cases}
\nu_0 = 0\\
\nu_{k+1} = \nu_k + k(2^{-1}\gamma'k + z') + 2^{-1}z' + \varepsilon'
\end{cases}
\end{equation} 
with $\gamma',z',\varepsilon' \in \mathbb{Z}_d$ restricted by \note{ta reda p√• vad sjutton som h√§nder h√§r egentligen}.
The gate that will be implemented in this report is the $T_3$ with $z' = 1, \gamma' = 2$ and $\varepsilon' = 0$, which is explicitly turn out to be 
\begin{equation}
T_3 = \begin{pmatrix}
1 & 0 & 0\\
0 & e^{2\pi i/9}& 0 \\
0 & 0 & e^{-2\pi i /9}
\end{pmatrix}.
\end{equation}

\note{something about qudit universality here maybe??}


\subsubsection{Non-Adiabatic Holonomic Quantum Computation}
Holonomic QC makes use of holonomies, which is to which extent parallel transport around some closed loop fails to preserve the transported data. Which in the case of Quantum mechanics means that a periodic system, $H(\mathbf{R}(0)) = H(\mathbf{R}(T))$, where $\mathbf{R}$ is a vector of parameters, gains an additional phase. This was first introduced by M.V. Berry\cite{berry} and thus the phase is usually refereed to as the Berry phase, but is more generally called the geometric phase, since the phase arises from the geometry rather than the dynamics of the system. The geometric phase exists also in non-adiabatic and non-abelian context, which gives room for more complex structures\cite{anandan1}\cite{anandan2}\cite{zee}. 
The in the adiabatic setting universal computation can be achieved through holonomies by transporting a set of control parameters along a loop(s) in a suitable space\cite{HQC}.

To see how the effect of adibaticy impacts the time evolution lets introduce a time dependent orthonormal ordered basis $\ket{k(t)} \in \mathcal{C}^1, k = 0,1,2,\dots,N$. The following calculation is based on the section on the adiabatic theorem in Sakurai\cite{Sakurai}.

 For an arbitrary state $\ket{\psi(t)}$, the Schr√∂dinger equation (\ref{eq:schro}) has a solution on the form 
\begin{equation}
\label{eq:gen_sol}
\ket{\psi(t)} = \sum_{n} c_n(t)e^{i\theta_n(t)}\ket{n(t)}
\end{equation}
where 
\begin{equation}
\theta_n(t) = -\int_0^t E_n(t')dt'
\end{equation}
for some coefficients $c(t)$ with $E_n(t)$ being the instantaneous eigenvalues of $H(t)$ at time $t$. Substituting (\ref{eq:gen_sol}) into the Schr√∂dinger Equation (\ref{eq:schro}), then by taking the inner product with $\bra{m(t)}$ and rearranging the result is a differential equation for the coefficients 
\begin{equation}
\dot{c}_m(t) = -\sum_{n}c_n(t) e^{i(\theta_n(t) - \theta_m(t))}\bra{m(t)}\pdv{}{t}\ket{n(t)}
\end{equation}
we note that $\bra{m(t)}\pdv{}{t}H(t)\ket{n(t)} = [E_n(t) - E_m(t)]\bra{m(t)}\pdv{}{t}\ket{n(t)}$,
then the equation for the coefficients can be rewritten as
\begin{equation}
\label{eq:non-ad}
\dot{c}_m(t) = -c_m(t) \bra{m(t)}\pdv{}{t}\ket{m(t)} - \sum_{n}c_n(t)e^{i(\theta_n(t) - \theta_m(t))}\frac{\bra{m(t)}\dot{H}(t)\ket{n(t)} }{E_n - E_m},\, n \neq m
\end{equation} 
in the adiabatic approximation\cite{adiabatensatz}, the second term can be taken to be zero since $H$ changes slowly and therefor $\dot{H}$ is small with respect to the first term. 
Then $c_n(t) = c_n(0)e^{i\gamma_n(t)}$ where $\gamma_n(t) = \int_0^t \bra{n(t')}\pdv{}{t'}\ket{n(t')} dt'$.
The general solution to a state would then be $\ket{\psi(t)} = \sum_{n}c_n(0)e^{i\gamma_n}e^{i\theta_n}\ket{n(0)}$, the time evolution operator in this case would be $\mathcal{U}(t,0) = \sum_{n}c_n(0)e^{i\gamma_n}e^{i\theta_n}$. In the adiabatic case a unitary can be constructed by controlling $\theta$ and $\gamma$.

In the non-adiabatic case some other means to control $\mathcal{U}$ must be engineered, since (\ref{eq:non-ad}) leads to state mixing and other unpleasantnesses. By removing the dependence on the dynamics of the system, the expressions takes on a much simpler form. 
Let the average energy of any to states be zero\cite{NHQC}, time dependence suppressed for clarity.
\begin{equation}
\bra{m}H\ket{n} = 0,\,\forall m,n
\end{equation} 
taking the time derivative gives 
\begin{equation}
\label{eq:non-ad-int}
\bra{m}\dot{H}\ket{n} + \bra{\dot{m}}H\ket{n} + \bra{m}H\ket{\dot{n}} = 0
\end{equation}
It turns out that all terms will be equal to 0, to see this 
take the inner product with $\bra{m}$ for the Schr√∂dinger equation for the state $\ket{n}$
\begin{equation}
i\bra{m}\ket{\dot{n}} = \bra{m}H\ket{n} = 0
\end{equation}
the same holds if we swap $m,n$, thus the two last terms in (\ref{eq:non-ad-int}) are equal to 0, then we have that $\bra{m}\dot{H}\ket{n} = 0$. By using this construction the second term in (\ref{eq:non-ad}) turns to 0 and the states do not mix with time. Another consequence is that the $\theta_n(t)= 0$. The evolution turns out to be 
\begin{equation}
\ket{\psi(t)} = \sum_{n}e^{i\gamma_n(t)}c_n(0)\ket{n(0)}
\end{equation}
making it only depend on the initial conditions and the geometrical phase.
Thus a unitary can be created by tracing the loop $C$ and one can obtain $U(T,0) = U(C) = \sum_{m,n}^N U_{mn}(C)\ket{m(0)}\bra{n(0)}$.
By parametrization of basis states and the loop can be chosen in such a way that $U$ correspond to a quantum gate.
